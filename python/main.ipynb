{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from numpy import save, load, array\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from Reference import make_references, Word_Count\n",
    "from search import find_valid_refs, get_all_words, find_unique_words \n",
    "from get_data import get_raw_verses, get_data\n",
    "from cfg import jesus_aliases, gospel_steps, books\n",
    "\n",
    "class Word:\n",
    "    def __init__(self, text='', count=int(0), references = []):\n",
    "        self.text = text\n",
    "        self.count = count\n",
    "        self.references = []\n",
    "        \n",
    "def find_word_count(w_objs, pattern):\n",
    "    found = False\n",
    "    for W in w_objs: \n",
    "        if W.text != pattern:\n",
    "            continue\n",
    "        else:\n",
    "            #print(W.text, W.count)\n",
    "            return W\n",
    "\n",
    "\n",
    "def make_objs():\n",
    "    fname = '../json/book-of-mormon.json'\n",
    "    xfname = '../json/book-of-mormon-flat.json'\n",
    "    raw = get_data(xfname)\n",
    "    data = get_raw_verses(raw)\n",
    "    Refs = make_references(data)\n",
    "    #raw_all_words = get_all_words(Refs)\n",
    "    raw_all_words = []\n",
    "    \n",
    "    for Ref in Refs:\n",
    "        for word in Ref.text:\n",
    "            raw_all_words.append(word)\n",
    "\n",
    "    raw_all_words.sort()\n",
    "\n",
    "    unique_words = []\n",
    "\n",
    "    for word in tqdm(raw_all_words):\n",
    "        if word in unique_words: continue\n",
    "        else: unique_words.append(word)\n",
    "    word_objs = []\n",
    "    \n",
    "    for word in tqdm(unique_words):\n",
    "        W = Word(text=word)\n",
    "        for _word in raw_all_words:\n",
    "            if _word != W.text:\n",
    "                continue\n",
    "            else:\n",
    "                W.count += 1\n",
    "        word_objs.append(W)\n",
    "    return word_objs\n",
    "\n",
    "def find_Words(w_sorted, pattern_list):\n",
    "    texts  = []\n",
    "    counts = []\n",
    "    valid = []\n",
    "    for pattern in pattern_list:\n",
    "        W = find_word_count(w_sorted, pattern)\n",
    "        if W is None:\n",
    "            continue\n",
    "        else:\n",
    "            #print(W.text, W.count)\n",
    "            valid.append(W)\n",
    "    return valid\n",
    "\n",
    "\n",
    "\n",
    "fname = '../json/book-of-mormon.json'\n",
    "xfname = '../json/book-of-mormon-flat.json'\n",
    "raw = get_data(xfname)\n",
    "data = get_raw_verses(raw)\n",
    "Refs = make_references(data)\n",
    "\n",
    "word_objs = load('./word-objs.npy')\n",
    "w_sorted = sorted(word_objs, key = lambda w: w.count, reverse=True)\n",
    "christ_aliases = find_Words(w_sorted, jesus_aliases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "christ_book_references = []\n",
    "christ_alias_with_ref = []\n",
    "sep = '\\t'\n",
    "for i in christ_aliases:\n",
    "    \n",
    "    v_refs = find_valid_refs(Refs,i.text)\n",
    "    new_refs = []\n",
    "    for ref in v_refs:\n",
    "        christ_book_references.append(ref.reference)\n",
    "        for book in books:\n",
    "            if book in ref.reference:\n",
    "                new_refs.append(book)\n",
    "        #print(i.text,ref.reference)\n",
    "    #print(i.text, sorted(new_refs))\n",
    "    output = i.text + sep +sep.join(new_refs) + '\\n'\n",
    "    #print(output)\n",
    "    with open('mentions-of-christ-seperate-count.csv', 'w+') as f:\n",
    "        f.write(output)\n",
    "#print(christ_book_references)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = books\n",
    "y = []\n",
    "area = lambda i:i*i\n",
    "\n",
    "for book in tqdm(books):\n",
    "    i = 0\n",
    "    for _ref in christ_book_references:\n",
    "        if book in _ref:\n",
    "            i += 1\n",
    "    y.append(i)\n",
    "    '''\n",
    "    text = book + ',' + str(i) + '\\n'\n",
    "    with open('mentions-of-christ.csv','a+') as f: \n",
    "        f.write(text)\n",
    "    '''\n",
    "#bubble_mpl = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(x,y)#, figsize=[4.0, 4.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_text= []\n",
    "gs_counts = []\n",
    "for step in gospel_steps:\n",
    "    W = find_word_count(w_sorted, step)\n",
    "    if W != False:\n",
    "        christ_names.append(W.text)\n",
    "        christ_counts.append(W.count)\n",
    "x = \n",
    "x = bom_books\n",
    "\n",
    "y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save('./word-objs.npy', word_objs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top-100-words.csv', 'w+') as f:\n",
    "    for w in w_sorted[:99]:\n",
    "        txt = w.text + ',' + str(w.count) + '\\n'\n",
    "        #print(txt)\n",
    "        f.write(txt)\n",
    "#save('./w_sorted.npy', w_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find top 300, will manually take out conjunctions and other common workds\n",
    "w_sorted = sorted(word_objs, key = lambda w: w.count, reverse=True)\n",
    "with open('top-300-words.csv', 'w+') as f:\n",
    "    for w in w_sorted[:299]:\n",
    "        txt = w.text + ',' + str(w.count) + '\\n'\n",
    "        #print(txt)\n",
    "        f.write(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#plt.bar(christ_names, christ_counts)\n",
    "#plt.bar(christ_names, christ_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ws = []\n",
    "\n",
    "for word in unique_words:\n",
    "    Ws.append(Word_Count(word))\n",
    "for W in Ws:\n",
    "    for x in raw_all_words:\n",
    "        if W.word == x:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
